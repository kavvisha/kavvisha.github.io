<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>DocSpace</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/full-width-pics.css" rel="stylesheet">
  <link href="css/extra_css.css" rel="stylesheet">
  <!-- js files -->
  <script src="js/jquery-3.4.1.js"></script>
  <script src="js/scripts.js"></script>



</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
    <div class="container">
      <a class="navbar-brand" href="#">DocSpace</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse navigation_handler" id="navbarResponsive">
        <!-- home
        domain
        milestones
        documents
        slides of past presentations
        about us
        contact us -->
        <ul class="navbar-nav ml-auto">
          <li class="nav-item active">
            <a class="nav-link clickscroll" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link clickscroll " href="bisinesssolution.html">Business Solution</a>
          </li>
          <li class="nav-item">
            <a class="nav-link clickscroll active_menu_item" href="researchprojectscope.html">Research Scope</a>
          </li>
          <li class="nav-item">
            <a class="nav-link clickscroll" href="milestones.html">Research Milestones</a>
          </li>
          <li class="nav-item">
            <a class="nav-link clickscroll" href="documents.html">Documents</a>
          </li>
          <li class="nav-item">
            <a class="nav-link clickscroll" href="presentations.html">Presentations</a>
          </li>
          <li class="nav-item">
            <a class="nav-link clickscroll" href="about.html">About us</a>
          </li>
          <li class="nav-item">
            <a class="nav-link clickscroll" href="contact.html">Contact us</a>
          </li>
          <li class="nav-item">
            <a class="nav-link clickscroll" href="policy.html">Privacy Policy</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>



  <section id="domain">
    <!-- Image Section - set the background image for the header in the line below -->
    <section class="py-5 bg-image-full set_header_image" style="background-image: url('images/dddd.jpg');">
      <!-- Put anything you want here! There is just a spacer below for demo purposes! -->

    </section>
    <!-- Content section -->
    <section class="py-5">
      <div class="container">
        <h1>Research Scope</h1>
        <div class="text_panel">

          <p class="lead">Literature Survey</p>
          <br>
          <h5>
            Text Classification
          </h5>
          <br>
          <p>
            Text classification is one of the major segments in a data classification system which is the procedure of organizing the type of text file automatically based on the given dataset. Several text classification concepts are available in
            the research world based on different supervised and unsupervised machine learning concepts.
          </p>
          <p>
            <b>Khudran Alzhrani, Ethan M. Ruddy, Terrance E. Boulty and C. Edward Chow "Automated Big Text Security Classification"[1]</b>
          </p>
          <p>
            The threat of leakage of sensitive information from inside attacks can be minimized by using DLP techniques. DLP techniques are composed with several phases as the discovering phase, detecting phase, protecting phase and monitoring phase
            [1].
          </p>

          <p>
            <ol>
              <li>Discovery Phase - Unlabeled data is scanned with a scanning agent and is passed to the detecting component for classification [1].</li>
              <li>Detecting Phase - Data is classified and labeled according to the sensitivity level.</li>
              <li>Protecting Phase - Based on the classification, information is either passed to the safe module or transmitted over unsecure paths. The system is developed to provide protection to the data in different approaches as treat
                transmitting data and data at rest [1].</li>
              <li>Monitoring Phase - At last, the monitoring module guarantees naming consistency and tracks clients' activities on the sensitive data inside the system [1].</li>
            </ol>
          </p>
          <p>
            <i>Figure I </i> illustrate the general components of a general DLP solution. This system is focused on developing the existing solutions to bring out a general statistical structure including text classification mechanisms [1].
          </p>
          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure I: A prototypical Data Leak Prevention (DLP) framework</i></p>
          </div>

          <p><b>
              Fang Miao, Pu Zhang, Libiao Jin, Hongda Wu "Chinese News Text Classification Based on Machine learning algorithm"
            </b></p>

          <p>
            Most of the developed classification algorithms are based on machine learning principles. A machine learning text classification system can be broken down into 4 components as text pretreatment, text representation, classifier training
            and
            classification. This classification system is a Chinese news text classifier which is based on K-nearest neighbor, Naive Bayes and Support vector machine [2].
          </p>

          <p>
            This research paper is based on the above mentioned components and this proposed system is developed to train the classifier module depending on the existing datasets which will classify the unclassified news. The shown Figure II
            illustrates the four components of a text classification system and the basic relationship between them [2].
          </p>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure II: Text Classification Model</i></p>
          </div>

          <p>The results of the training set and the test set derived from the news corpus of the Fudan University after classifying from this system is shown below in <i>Table I.</i></p>
          <div class="img_box_w_cap">
            table!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Table I: Result of Classification</i></p>
          </div>

          <p>Based on the above collected results the precision value, recall and F-value is calculated. The obtained results are indicated on the below <i>Table II.</i></p>
          <div class="img_box_w_cap">
            table!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Table II: Performance Evaluation</i></p>
          </div>

          <p>
            After analyzing the data in <i>Table I</i> and <i>Table II </i>, it is clear that the precision value, recall and the F-value are the highest in the SVM algorithm. However, the SVM algorithm is time consuming. Therefore it is only
            suitable for small datasets. Other two algorithms produced similar results [2].
          </p>

          <p>
            <b>
              Ge Peng, Sipei Liu and Jin Wang "Sensitivity-Proof Content Advertising Based on Two-Stage Text Classification" [3]
            </b>
          </p>

          <p>
            Social media is one of the most prominent information sharing platforms in the modern world. There are some advantages as well as some disadvantages of using social media. Sharing of the sensitive information in an unauthorized manner is
            one of the major disadvantages of social media. Sex-related information, violate news are some of them. This research paper is based on content classification based on sensitivity level. The proposed system is developed under two stages
            [3].
          </p>

          <p>
            <ol>
              <li>Advertisement classification</li>
              <li>Sensitivity detection</li>
            </ol>
          </p>

          <p>
            The solution heavily focuses on two classifiers, general advertisement classifier and sensitivity detector. General advertisement classifier will classify the content based on the text and assign the advertisements to the respective Ad
            class. The sensitivity detector will then classify the pre-classified advertisements again based on the sensitive information to produce results. The hierarchical architecture developed within the system enables the functioning of the
            system efficiently which is shown in the <i>Figure III</i> below [3].
          </p>
          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure III: Architecture of two-stage Classification</i></p>
          </div>

          <p>The policy implemented for the classification process is shown below in <i>Table III.</i></p>
          <div class="img_box_w_cap">
            table!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Table III: Decision Policy Table</i></p>
          </div>
          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure IV: Text Classification Methodology</i></p>
          </div>

          <h5>Image Classification </h5>
          <p>
            Another method to classify files is based on the image content of the file. Image classification is referred to as a process that is able to classify an image according to its visual content. An image classification algorithm has to be
            designed to analyze the content of the image. David Kaeli, in his book which is heterogeneous Computing with OpenCL 2.0 states how important the BoW model is related to document classification and natural language processing. Furthermore
            he highlights the fact that the BoW model is used to classify images. For this purpose, features of the image should be identified and should be fed for the machine learning algorithm. A feature generation algorithm can be used to convert
            an image to a set of features which is also called as the signature of the image.
          </p>
          <p>
            A high level algorithm for image classification includes
            <ul>
              <li>Feature generation </li>
              <li>Clustering</li>
              <li>Histogram building steps</li>
            </ul>
          </p>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure V: High level algorithm for Image Classification</i></p>
          </div>

          <p>
            Sergios Theodoridis and Konstantinos Koutroumbas in their book, Pattern Recognition, define diffusely about features, feature hectors and classifiers. By showing two images with distinct regions inside it, authors try to convince the fact
            that the two regions of the image are visually different. This process is aided by already available image databases with a number of patterns which leads to machine learning.

          </p>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure VI: Image Comparison </i></p>
          </div>

          <p>
            Moreover, Robert C. Weih, Jr. and Norman D. Riggan, Jr. proposed OBJECT-BASED CLASSIFICATION VS. PIXEL-BASED CLASSIFICATION: COMPARATIVE IMPORTANCE OF MULTI-RESOLUTION IMAGERY and verbosely defined about the 3 main techniques of image
            classification in remote sensing [6].
            <ul>
              <li>Unsupervised Image Classification</li>
              <li>Supervised Image Classification</li>
              <li>Object-based Image Analysis</li>
            </ul>
            The two most common approaches are said to be Unsupervised and Supervised techniques but lately object based classification has been used more for work related to high resolution data.
            <ul>
              <li>
                Unsupervised classification steps are Generating clusters and Assigning classes
                <div class="img_box_w_cap">
                  img!
                  <img class="fullsizeimage" src="" alt="">
                  <p><i>Figure VII: Unsupervised Classification </i></p>
                </div>
              </li>

              <li>
                Supervised classification steps are namely Select training areas, Generating signature files and classification.
                <div class="img_box_w_cap">
                  img!
                  <img class="fullsizeimage" src="" alt="">
                  <p><i>Figure VIII: Supervised Classification</i></p>
                </div>
              </li>

              <li>
                Object based classification steps are namely Performing multiresolution segmentation, Selecting training areas and Classification.
                <div class="img_box_w_cap">
                  img!
                  <img class="fullsizeimage" src="" alt="">
                  <p><i>Figure IX: Object based Classification</i></p>
                </div>
              </li>
            </ul>

          </p>
          <h5>
            Prevention Techniques
          </h5>
          <p>In real world situations there are a number of complex policies, in these access decisions depend on the rule. According to the different application rules are coming, for example, from organizational regulations, practices and
            government laws. To develop the access controls, the system needs to ensure that the availability of the resources, confidentiality and integrity of the data.</p>
          <p>There are three main types of access control policies.</p>
          <p>Mandatory access control (MAC), in this policy users has no authority to override the policies and it is controlled centrally by the security policy administrator. This is used when the use of resources is determined by the
            characteristics of the resource and the subject. Here the resource owner does not have a say in controlling access. The security policy administrator defines the utilization of resources and their access policy, which cannot be overridden
            by the end users, and the policy, will decide who has authority to access the particular programs and files. MAC is mostly used in a system where confidentiality is the priority.[3]</p>
          <p>Discretionary access control (DAC), this policy Contrast with Mandatory Access Control (MAC) which is determined by the system administrator while DAC policies are determined by the end user with permission. So there each resource will
            have a resource owner. In DAC, a user has complete authority over all resources it owns and also determines the permissions for other users who have those resources and programs.[4]</p>
          <p>Role-based access control (RBAC), this policy is rather simple in comparison to others. In RBAC roles are assigned by the system administrator statically. In which access is controlled depending on the roles that the users have in a
            system. (RBAC) is mostly used to control the access to computer or network resources depending on the roles of individual users within an organization. In this context we discuss the different access control policies and models that have
            been proposed by the researchers, whilst finding the current status of access control systems and their low level implementation in terms of security mechanisms. This review gives the idea of different access control policies to develop
            the access control systems and gives the overview comparison of the different security policies and their mechanisms.[4]</p>
          <p>Throughout this research paper Role Based Access Controls are put into use. After a successful user login, the role of the user will be identified and since the permissions are mapped to the roles beforehand, the logged in user will only
            be able to perform the specified activities on the files.[4]</p>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure X: Role Based Access Controls</i></p>
          </div>

          <p>The system protection is based on the permission that describes a given access right to a particular object or set of objects. In the RBAC model we are dealt with unauthorized access to the computer system resources and data [29]. Since
            we have considered only the access rights that users are required to execute a particular transaction on a particular object from the defined set of objects.[4]</p>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure XI: User role permission mapping </i></p>
          </div>

          <p>A permission p is a pair < trans, object>, where trans represents the transaction that executes on the set of objects that is object .Consider P indicate the universal set of permissions, Trans indicate the universal set of transactions,
              and Obj indicates the set of objects. We can define the association between permission/transaction and permission/object with the following functions. Trans (p) : P → Tr, It gives the associated transaction to the specified permission
              p. ObP (p) : P → 2Obj ,It gives the associated set of objects to the specified permission p. A role is created by collecting permissions according to the functional and logical requirements to this role should represent. Each role has a
              name associated with this and it uniquely identifies this role in the system. A role r is a pair of < rn, pset>, where rn indicates the role name and pset indicates the set of role permissions. The mapping between roles and permissions
                can be defined with the following function: PR(r): R → 2P, It gives the associated set of permissions to the specified role r. Here R indicates the universal set of roles. While allocating permissions to roles it is needed to ensure
                the principle of least privilege that is each role should have only required rights for its functional requirements.[4]
          </p>

          <p>It is needed to take necessary measures to achieve the integrity and security of data. The classified data should only be accessed by the authorized individuals while preventing the access by unauthorized individuals. A paper presented
            by Rizwana Shaikh,Dr. M. Sasikumar mentioned Data can be classified based on several factors as outlined by the above figure. It mentions that Access Control, Content and Storage can be used as characteristics to classify data. Likewise,
            we can use the characteristics which we use to classify text and image as a base to preserve the classification levels that will be implemented in the proposed data classification scheme [3]. Another paper presented by Bokefode Jayant. D,
            Ubale Swapnaja A, Apte Sulabha S, Modani Dattatry G, it is declared access control based models can be used for achieving security[4]. Mainly access control is based on three models; Discretionary Access Control(DAC), Role Based Access
            Control(RBAC) and Mandatory Access Control(MAC). Out of those three Role Based Access Control best suits the proposed data classification scheme. In RBAC, there are defined sets of roles which predefined permissions on objects. The users
            are assigned to the roles, the user will only be able to perform the tasks defined for that particular role [4]. </p>

          <p>Access Control will be effective only if the users are authenticated before that. There are several authentication mechanisms currently ruling the authentication system.</p>

          <p>Authentication can be made possible in different ways. A basic authentication technique is a page containing a login form. After filling out the login form, the input data will be validated against a server and will return a session
            cookie. The idea behind cookies is that they help to maintain continuity and states on the web. When the user visits the same website again, the browser sends the cookie to the web server which uses this cookie to identify the user. The
            purpose of a cookie is to provide information for the subsequent server-browser communications. For instance, a merchant website could use a cookie that contains the user’s name and credit card number, and this information can be used to
            make future payment transactions easier.</p>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure XII: Cookie Authentication</i></p>
          </div>

          <p>If the credentials are correct, the system continues to step two, which returns a cookie back to the system. The client then sends this cookie to the service. Based on this cookie, it decides whether the user is granted access to the
            data. In some cases, the service contacts the authentication server to verify whether the cookie is still valid.</p>
          <p>While the user stays logged in, the cookie would be sent along with every subsequent request. The server can then compare the session id stored on the cookie against the session information stored in the memory to verify the user’s
            identity and it sends the response with the corresponding state!</p>
          <p>A token-based authentication mechanism has a different approach. A user enters the name and password into the client (client means the browser or mobile devices etc.). The client then sends these credentials (i.e. username and password)
            to the Authorization Server. Then the Authorization Server authenticates the client credentials (i.e. username and password) and then it generates and returns an access token. This Access Token contains enough information to identify a
            user and also contains the token expiry time the client application then includes the Access Token in the Authorization header of the HTTP request to access the restricted resources from the Resource Server until the token is expired.</p>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure XIII: Token Based Authentication</i></p>
          </div>

          <p>This concept alone takes care of many of the problems with having to store information on the server. The biggest difference here is that the user’s state is not stored on the server, as the state is stored inside the token on the client
            side instead.</p>

          <h5>
            File Modification Detection
          </h5>
          <p>
            Data protection is important, critical, and vital for any organization. Loss of data effect the privacy and security of the organization. In the new era data has grown up massively in terms of volume. Data has value and if it is fall in
            to the wrong hand it can have drastic consequences. It has been predicted the volume of data would reach 44 trillion gigabytes by the year 2021. And protecting data necessitates robust DLP. A report from Gartner predicts DLP to grow at
            10% [1]. There have theft for sensitive data earlier, but they have become more frequent nowadays.
          </p>
          <p>
            Data breaches with the loss of sensitive enterprises can affect reputation of the enterprises, cause financial loss and it may have to face lawsuits sometimes. So it is vital to know the importance of data protection, as a research team
            have to find smart and efficient way to prevent data loss and detect data modification in an organization caused by intentional or unintentional attack to the data [2]. So, it’s very clear that enterprises are in need to implement a
            robust system along with DLP technologies.
          </p>

          <p>
            This writing is mainly focusing on integrity of the stored data and an innovative solution that allows to detect intentional/unintentional modification of data while increasing the effectiveness of the system. The author is proposing
            several solutions based on the literature survey and finally proposing a novel scheme relying on fuzzy hashing for the detection of unauthorized data modification by the internal users of the system.
          </p>

          <p><b>Hashing standards to detect the file modification</b></p>

          <p>
            Hashing is a cryptographic sequence of letters and numbers generated when a file is analyzed by a hashing algorithm. When it comes to ensuring the integrity of file or file content the best answer is to use hashes. It is a crucial Data
            Structure which is designed to implement a special function named the Hash function which is used to map a given value with a key for faster access of elements. The efficiency of mapping depends on the efficiency of the hash function
            used.
          </p>

          <p>
            For cryptographic hash function, the following properties are required: Preimage resistance: it is computationally infeasible to find any input which hashes to any pre-specified output. Second preimage resistance: it is computationally
            infeasible to find any second input which has the same output as any specified input. Collision resistance: it is computationally infeasible to find a collision, i.e. two distinct inputs that hash to the same result [3]. Therefore, it is
            evident that hashing can be utilized to exactly figure out whether a file is altered or not. Research world proved that there are several hashing algorithms out in the world to achieve integrity of our data. There are 2 most widely used
            algorithms so far that are MD5 and SHA-256.
          </p>

          <p><b>Message Digest5</b></p>

          <p>
            MD stands for Message Digest and describes a mathematical function that can take place on a variable length string. The number 5 simply depicts that MD5 was the successor to MD4. MD5 is essentially a checksum that is used to validate the
            authenticity of a file or a string and this is one of its most common uses. It makes large amounts of information to be compressed into a confidential format before signing the private key by digital signatures (that is, any length byte
            string is transformed into a certain length of big integer) [4].
          </p>

          <p>
            Md5 hashes goes through several steps to compare 2 files and verify the integrity of files.
          </p>

          <ol>
            <li>Padding bit
              <ul>
                <li>
                  <p>Without loss of generality of the file content, it supposes that the original data padding is always added until its length in bits is congruent. </p>
                </li>
              </ul>
            </li>

            <li>
              Padding the length of data
              <ul>
                <li>A 64-bit representation of the length of bits of the original message is appended to the result of above step. It is present by two 32-bit digits. At this time, the length of data is filled to a multiple of 512.
                  <div class="img_box_w_cap">
                    img!
                    <img class="fullsizeimage" src="" alt="">
                    <p><i>Figure XIV: MD5 Working principle of an iterated hash function</i></p>
                  </div>
                </li>
              </ul>
            </li>

            <li>
              Initialize MD5 Parameters
              <ul>
                <li>
                  Using the original data which is in the updated file it would calculate the hash value.
                </li>
              </ul>
            </li>

            <li>
              Bit operation functions
              <ul>
                <li>
                  Define four-bit operation functions respectively.
                </li>
              </ul>
            </li>

            <li>
              Main transformation process
              <ul>
                <li>
                  The number of main loops in this algorithm is the number of 512-bit information groups. The main loop has four rounds, each round carries out 16 operations, so the total of operations are64 steps.
                  <div class="img_box_w_cap">
                    img!
                    <img class="fullsizeimage" src="" alt="">
                    <p><i>Figure XV: One step of the compression function</i></p>
                  </div>
                </li>
              </ul>
            </li>
          </ol>

          <p>Parameters of MD5</p>
          <p>Below equation shows a single MD5 operation. </p>
          <p>
            <ol>
              <li>
                Default Parameters
                <ul>
                  <li>
                    <math>
                      a = b + ((a + Process P (b, c, d) + M[i] + t[k]) <<< s) Here:- a, b, c, d=are Chaining variables Process P=A non linear </math>

                  </li>
                  <li>
                    <math>
                      • operation M[i] =For M[q x 16 + i ], which is the ith 32-bit word in the qth 512-bit block of the message t[k]=a constant <<<s=circular-left shift by s bits </math>

                  </li>
                </ul>
              </li>

              <li>
                Actual Parameters
                <ul>
                  <li>
                    Key Length: 64 bits, 128 bits, 256 bits , 512 bits
                  </li>
                  <li>
                    Block Size: 128 bits
                  </li>
                  <li>
                    Cryptanalysis: Resistance Strong against Digital Certificate and very fast on 32-bit machines Security Secure
                  </li>

                  <li>
                    Rounds: 4
                  </li>
                  <li>
                    Steps: 16
                  </li>
                </ul>
              </li>
            </ol>

            <p><b>Secure Hash Algorithm 256</b></p>

            <p>
              SHA-256 is an emerging technology that is considered a stronger option for conducting a checksum for file integrity. SHA-256 uses 256-bits compared to 128 used for an MD5, which exponentially increases the different letter/number
              combinations that can be generated and decreases the plausibility of a collision or repeatability, which theoretically exists with MD5 [5].
            </p>

            <div class="img_box_w_cap">
              img!
              <img class="fullsizeimage" src="" alt="">
              <p><i>Figure XVI: SHA-256 mechanism</i></p>
            </div>

            <p>
              SHA 256 is also going through several rounds of steps to obtain the message digest [7].
            </p>

            <ul>
              <li>
                Step 1: - Padding / Add Padding to the end of the genuine message length is 64 bits and multiple of 512.
              </li>

              <li>
                Step2: - Appending length In this step the excluding length is calculated
              </li>

              <li>
                Step3: - Divide the Input into 512-bit blocks in this step we divide the input in the 512 bit blocks
              </li>
              <li>
                Step4: - Initialize chaining variables. During this step we are initializing chaining variables here we initialize 5 chaining variables of 32 bit each=160 bit of total.
              </li>
              <li>
                Step5: - Process Blocks
              </li>

            </ul>

            <ol>
              <li>Copy the chaining variables </li>
              <li>Divide the 512 into 16 sub blocks </li>
              <li>Process 4 rounds of 20 steps each</li>
            </ol>
          </p>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure XVII: SHA-256 mechanism</i></p>
          </div>


          <p>Parameters of SHA 256</p>

          <p>Below equation shows a single SHA operation. </p>
          <ol>
            <li>
              Default Parameters
              <ul>
                <li>abcde(e+process p_s5(a)+W[t]+k[t]),a,s30(b), c, d</li>
                <li>Here:- a, b, c, d, e =chaining variables </li>
                <li>Process p =status of logical operations st =<<< W[t]=derived other 32 bits bytes </li>
                <li>K[t]=five additives constants are defined</li>
              </ul>
            </li>

            <li>
              Actual Parameters
              <ul>
                <li>Key Length: 128 bits </li>
                <li>Block Size: 160 bits</li>
                <li>Cryptanalysis: Resistance Strong against Digital Certificate. </li>
                <li>Rounds: 4 </li>
                <li>Total Steps: 20</li>

              </ul>
            </li>
          </ol>

          <div class="img_box_w_cap">
            table!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Table IV: Comparison between MD5 and SHA</i></p>
          </div>

          <div class="img_box_w_cap">
            img!
            <img class="fullsizeimage" src="" alt="">
            <p><i>Figure XVIII: Performance chart of hashing algorithms</i></p>
          </div>

          <p><b>Create custom event log and port listening</b></p>

        </div>
        <div class="text_panel">

          <p class="lead">Research Gap</p>
          <p>
            No matter how advanced the current technology is, there is still a slow development and
            inventions in the cause of securing data at rest. The monopoly that the high standard
            organizations maintain to keep their social reputation is a major reason for this. They demotivate
            small scale organizations in securing their personal information which will enable them to collect
            data through internal attacks. For example top rated stock broking firms use employees of
            upcoming stock broking companies to collect information about pending bids by paying them.

          </p>
          <p>
            Throughout history various organizations and governments introduced different solutions to
            address the problem of Data Loss. The Enigma machine can be considered as one such solution
            which was able creates a turning point in the field of Cyber Security. But in the recent past,
            traditional countermeasures such as manually controlled inbound storage spaces or file based
            storage systems have proven ineffective against internal attacks causing serious problems. This
            has created a huge loophole in the field of information security making it really difficult for the
            officials to control. Due to the negligence of the authorities, a huge gap is now created making it
            difficult for the security enthusiasts to recover soon.
          </p>
          <p>
            On the other hand with the development of technology and the rapid increment of the use of the
            internet, security of sensitive information is at a higher risk. Usually these problems are
            addressed through enforcing security measures to the whole system. But modern advanced
            technologies are continuously causing problems to these measures proving them unreliable,
            expensive and resource consuming. Therefore classification of data can be considered as another
            approach designed to protect information other than enforcing security measures on the system
            as a whole. Although the approach is presented and several systems are developed, there is a
            requirement for a single integrated hybrid system which can classify documents.
          </p>
          <p>
            Organizations store heaps of information. Controlling, managing and manipulating these
            information is a huge challenge to any organization in the presence of modern technology. Also
            these information should be classified based on the sensitivity level in order to fulfill the security
            requirements of the organization. Although the prevailing solutions are capable of classifying
            information based on few specific purposes, there is no one integrated machine learning module
            to classify organizational documents which are specific to various industry domains.
          </p>
          <p>Moreover due to the fact that modern technologies are rapidly used in most of the organizations
            worldwide, there is a huge gap in the industrial world for technicians who are capable of
            handling latest technology based products. One main example to prove the above point is that
            there should be a specially recruited team to configure the Banking Software everyday which is
            just running the same piece of code in all machines. But there is a possibility to reduce the IT
            support team if the configuration is automated using an understandable user interface which does
            not need any technical knowledge about that.</p>
          <p>It is clear that although there are several attempts carried out in this purpose, a solution which
            can address the above mentioned problems is still in need. Therefore the main focus of this
            research is to develop a solution which will cover all the required aspects and to make DocSpace
            the best among the list.</p>
        </div>
        <div class="text_panel">
          <p class="lead">Research Problem</p>
          <p>
            With the expansion of modern technology, the lifestyle of people is mostly managed and relied
            on their computers and mobile phones to an increasing extent. On that premise, File
            classification can be introduced as a technique to the modern storage systems which can be
            introduced as a hierarchical arrangement of classification levels in an efficient approach to
            address the problem of how to secure information. But the major problem in the industrial world
            is that there is no solution implemented to classify documents using the principle idea of using
            file properties such as date and time the file was created, size of the file, owner and access
            patterns and classifies files.
          </p>
          <p>
            However to address this problem, technological approaches should be analyzed covering the
            main objective. Based on the developed classification structures it was clear that machine
            learning technologies are used to achieve the utmost goal of classifying files in an effective
            manner. But it was required to analyze on how to come up with a solution which can introduce a
            unified methodology to classify and secure data with the aid of security levels which can be
            considered as a valuable solution to the industrial space over many security related issues.
            However, the requirement of analyzing data before classifying in order to get a clear
            understanding about the data that is about to be classified should be looked after to obtain the
            maximum output. Although several organizations have implemented different standards and
            policies, lack of understanding of the general public on this matter is still acting as a barrier
            making it difficult to step up as a community. Moreover, it is required to find out how to
            implement appropriate measures to prohibit accessing files in lower security levels to higher
            security levels without proper authorization. This will enable the small scale organizations to
            keep their sensitive information private and also to come up with innovative solutions which will
            make them unique and successful. Although governments are still not keen on paying some
            attention to address this issue as a nation, the impact made by intruders and attackers on
            governing bodies is still at a very high level.
          </p>
          <p>
            Organizations are experiencing serious problems due to the Higher Cost and Higher Resource
            Consumption Rate when Implementing Data Prevention Techniques. As discussed in the
            previous section this is one of the main reasons why organizations are neglecting the security of
            their data. Further Most of existing systems require Expert Knowledge to achieve Maximum
            Performance. Therefore it is needed to wait for a technical support officer to make the required
            changes in order to proceed with the work in any kind of minor uncleariblity. Based on the above
            details it is clear that a solution with lower resource consumption and lower implementation cost
            is required. Further the system should be able to address the problem of complex operational
            knowledge. There is no evidence to prove the existence of a Single Integrated Solution that can
            classify industrial specific files based on the level of sensitivity of the information.
          </p>
          <p>
            The most important requirement in developing security solutions is the control of the access
            aspect of the system. The particular solution won’t be even to clothe term security if the proper
            access controls are not there. At the present time, the security solutions which are using access
            control mechanisms couples with authentication mechanisms which are obsolete and which are
            highly prone to attacks. Therefore, there is a clear line between the use of the proper access
            control mechanisms along with industry standard authentication protocol to secure the resources
            which need to be protected and the securing of users which are using the security solutions.
          </p>
          <p>
            There is also a major problem in the process of updating from the current security level of the
            file after each modification to improve accuracy. This can be considered as a problem based on
            securing the classified files which are stored. Comparatively there is a lack of focus on securing
            the classified files in both traditional classification methods and latest classification methods.
            Therefore it is required to find out how to keep the files continuously safe. This proposed model
            is based on the question how to develop a single integrated based hybrid data classification
            system using high level Microservice architecture to prevent intentional or unintentional
            misbehaviors.

          </p>
        </div>
        <div class="text_panel">
          <p class="lead">Research Objectives</p>
          <p>
            Almost all the activities of the world have some sort of digital intervention to it. Let it be simply
            reserving a book from a library to voting. All these services or products take the advantage of
            digital devices and systems to speed up the process or to have an effective and efficient outcome.
            Digital devices and systems use data as a main input. Therefore, it is crucial that the data which
            is fed into these systems are kept and handled in a secure and organized manner. Data
            classification is meant to set labels and categories for data based on the sensitivity of data.</p>

          <p>In the recent past, traditional countermeasures have proven inefficient when dealing with inside
            attacks. Classification of data is one of the most prominent and modern security measures
            followed by organizations in order to obtain DLP from insider attacks. With the rapid
            enhancement of the technology and the continuous nature of the information collection process
            an efficient system to classify data is required. After analyzing the aspects of the research
            problems, a set of specified objectives were constructed to design a new product covering all the
            identified gaps.</p>

          <p><b>Main Objective</b></p>

          <p>The main objective of this research is to develop machine learning based single integrated hybrid
            data classification solution to perform text and image classification together, to re-classify the
            updated classified files and to prevent intentional or unintentional miss behavior using the
            classification implemented. Further the specification of the solution to the industrial world which
            the prevailing solutions are not capable of was also focused throughout the process. In addition
            to the main objective several specific objectives were designed to increase the productivity and
            efficiency of the product while maintaining the commercial quality. The total product which
            includes 4 major components is designed completely based on this objective scope.</p>


          <p><b>Specific Objectives</b></p>

          <p>The main focus of this section is on the secondary objectives that can be either specific or
            different to each component related to the product. Although they are described under the
            secondary objectives section, it is really important to keep in mind that these conditions should
            also function accordingly in order for the complete system to run. Also to ensure that the
            assumptions made during the project development period.</p>

          <p>
            <ul>
              <li>Collection of text and image documents based on the relevant industry domain to train
                the classifier.</li>
              <li>Categorization of the documents into different classification levels based on the global
                data standards.</li>
              <li>Selection and implementation of supervised machine learning techniques for
                classification.</li>
              <li>Implementation of OCR based image to text conversion algorithm.</li>
              <li>Implementation of token based authentication mechanism.</li>
              <li>Development of security levels and user roles based on role based access control
                mechanisms.
              </li>
              <li>Maintenance of the continuous classification process through Hashing.</li>
              <li>Maintaining the functional independence of the components to make sure that the final
                product can be switched based on the industry audience.</li>
              <li>Implementation of a user-friendly environment to allow the users to operate the system
                with minimum knowledge to gain maximum performance.</li>
              <li>Ensure that the designed components will not make any difference to the cost estimation
                of the final product. </li>
              <li>Development of the components to function based on minimum resources consumption
                but maximum efficiency.</li>
              <li>Ensure that the solution is easily accessible and portable while maintaining the security.</li>
              <li>Adoption of a commercially valuable development structure and a sustainable outcome.</li>
            </ul>
          </p>
          <p>

          </p>

        </div>

        <div class="text_panel">
          <p class="lead">Methodology</p>
          <p>
            zzzzzzz</p>

        </div>
        <div class="text_panel">
          <p class="lead">Audience</p>
          <p>The factors that are explained in the previous sections prove that one of the major reasons for not
            using classification as a security implementation to secure data is the lack of focus on developing
            a solution that is fixed to a wider range of users. As an example the second solution explained
            under literature survey is based on Chinese news classification which is useful only to a minor
            social sector. Therefore this research is developed with the objective of expanding the audience
            to motivate the organizations to use these types of solutions.</p>
          <p>Therefore DocSpace is designed based on a complex mechanism which is advanced enough to be
            used in any industry domain where data classification is required. It can vary from industries
            which require lower level security implementations such as Education, Agriculture and
            Transportation to industries which require higher level security implementations such as
            Military, Banking and Finance. However the dataset which is to be used should be changed and
            tweaked based on the industry that the product will be used. For the development purpose we
            have trained the model based on the Banking and Finance industry which is one area where a
            solution similar to this is essential.</p>



        </div>
      </div>
      </div>

      </div>
    </section>
  </section>



  <!-- Footer -->
  <footer class="py-5 bg-dark">
    <div class="container">
      <p class="m-0 text-center text-white">Innovation is what the World lacks at present. Products are developed everywhere
        everyday but what really matters is how we can serve the world with our productions. That is
        where innovation matters.
      </p>
      <br>
      <div class="find_us_footer">
        <p>Follow Us on LinkedIn</p>
        <div class="findus_person">
          <a href="https://www.linkedin.com/in/dilshan-christopher" class="clickscroll btn btn-default">Dilshan Christopher Jayakody</a>
        </div>
        <div class="findus_person">
          <a href="https://lk.linkedin.com/in/dilshan-umindu" class="clickscroll btn btn-default">Dilshan Umindu</a>
        </div>
        <div class="findus_person">
          <a href="https://www.linkedin.com/mwlite/in/sashini-gunawardhana-08661a164" class="clickscroll btn btn-default">Sashini Gunawardhana</a>
        </div>
        <div class="findus_person">
          <a href="https://www.linkedin.com/in/aathika/" class="clickscroll btn btn-default">Aathika Salam</i></a>
        </div>
      </div>
      <br>
      <p class="m-0 text-center text-white">Copyright &copy; DocSpace 2019</p>
    </div>
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</body>

</html>